{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49F9n0qO-U8o",
        "outputId": "4417ae49-edeb-4982-dcee-859afe04bbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==1.0.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "PpBoh8ky-ZLy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Implement the forward and backward function for NN.\n",
        "# 2. Set the network structure as [64, 30, 10]\n",
        "    #  a) Try to use sigmoid function as activation function.\n",
        "    #  b) Try using the ReLU activation function.\n",
        "    #  c) Try using the tanh activation function"
      ],
      "metadata": {
        "id": "Tp4XP38h-e20"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(y):\n",
        "  # Find the unique categories and their inverse indices\n",
        "  categories, inverse = np.unique(y, return_inverse=True)\n",
        "\n",
        "  # Create the one-hot encoded matrix\n",
        "  one_hot = np.zeros((y.size, categories.size))\n",
        "  one_hot[np.arange(y.size), inverse] = 1\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "v274MCBteFWw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# one-hot encoding\n",
        "y_train_one_hot = one_hot(y_train)\n",
        "y_test_one_hot = one_hot(y_test)"
      ],
      "metadata": {
        "id": "MFGBy7ac-nYv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9p40oMa7r-1",
        "outputId": "c67b53b3-daf5-4020-cc68-bd73216f85c9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -0.34169755, -0.46336049,  0.50836462, -2.54590607,\n",
              "       -1.03722581, -0.40623424, -0.13101874, -0.06103492, -0.61725402,\n",
              "        0.30881425,  0.00348328, -2.18152552, -1.35608548, -0.52465505,\n",
              "       -0.13336005, -0.04991522,  0.12851911,  1.08857992, -0.19343737,\n",
              "       -1.16010978, -1.27307852, -0.552537  , -0.11409248, -0.03733267,\n",
              "        0.86365151,  1.13744682, -1.16195968, -1.60835913, -1.28296188,\n",
              "       -0.62554872, -0.04573894,  0.        ,  1.09151514,  1.34318585,\n",
              "       -1.12678131, -0.90106555, -1.13185292, -0.81347241,  0.        ,\n",
              "       -0.06519029,  0.82828946,  1.39981472, -0.82540858,  0.69177178,\n",
              "        1.17865528, -0.33784246, -0.09403434, -0.03963009,  0.15955797,\n",
              "        1.14244768,  0.64507954, -1.42282149,  0.68917912,  1.47990131,\n",
              "       -0.21608405, -0.02638899, -0.30677646, -0.49962244, -0.246272  ,\n",
              "        0.84804385,  1.05270303,  0.45952251, -0.19710003])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x, deriv=False):\n",
        "  sigmoid_output = 1 / (1 + np.exp(-x))\n",
        "  if deriv:\n",
        "    return sigmoid_output * (1 - sigmoid_output)\n",
        "  return sigmoid_output\n",
        "\n",
        "def relu(x, deriv=False):\n",
        "    if deriv:\n",
        "        return np.where(x > 0, 1, 0)\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def tanh(x, deriv=False):\n",
        "  if deriv:\n",
        "    return 1 - np.tanh(x)**2\n",
        "  return np.tanh(x)"
      ],
      "metadata": {
        "id": "GwKRuRk26oOq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNets:\n",
        "  def __init__(self, input_size, hidden_size, output_size, *, act=\"sigmoid\"):\n",
        "    self.activation = sigmoid if act == \"sigmoid\" else relu if act == \"relu\" else tanh\n",
        "    self.b1 = np.zeros((1, hidden_size))\n",
        "    self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "    if act == \"relu\":\n",
        "      self.w1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n",
        "      self.w2 = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)\n",
        "    else:\n",
        "      self.w1 = np.random.randn(input_size, hidden_size)\n",
        "      self.w2 = np.random.randn(hidden_size, output_size)\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    self.z1 = np.dot(x, self.w1) + self.b1 #First layer\n",
        "    self.a1 = self.activation(self.z1)\n",
        "    self.z2 = np.dot(self.a1, self.w2) + self.b2  #Output layer\n",
        "    self.a2 = self.activation(self.z2)\n",
        "    return self.a2\n",
        "\n",
        "  def backprop(self, x, y):\n",
        "    size = len(x)\n",
        "    # Error at output layer\n",
        "    output_error = self.a2 - y\n",
        "    output_delta = (2/size) * output_error * self.activation(self.a2, deriv=True)\n",
        "\n",
        "    # Error at hidden layer\n",
        "    hidden_error = output_delta.dot(self.w2.T)\n",
        "    hidden_delta = hidden_error * self.activation(self.a1, deriv=True)\n",
        "\n",
        "    # Update weights and biases\n",
        "    self.b1 -= self.alpha * np.sum(hidden_delta, axis=0, keepdims=True)\n",
        "    self.b2 -= self.alpha * np.sum(output_delta, axis=0, keepdims=True)\n",
        "    self.w1 -= self.alpha * x.T.dot(hidden_delta)\n",
        "    self.w2 -= self.alpha * self.a1.T.dot(output_delta)\n",
        "\n",
        "  def train(self, X, Y, *, learning_rate=0.01, epochs=1000):\n",
        "    self.alpha = learning_rate\n",
        "    for i in range(epochs):\n",
        "      for x, y in zip(X, Y):\n",
        "        x = x.reshape(1, -1)  # Reshape x to (1, 64) before passing to feedforward and backprop\n",
        "        self.feedforward(x)\n",
        "        self.backprop(x, y)\n",
        "      if i%20 == 0:\n",
        "        print(f\"Epoch {i} completed ---------------->\")\n",
        "        print(f\"The accuracy score is {self.accuracy(Y, self.predict(X))}\")\n",
        "\n",
        "  def predict(self, X):\n",
        "    return [np.argmax(self.feedforward(x)) for x in X]\n",
        "\n",
        "  def accuracy(self, Y, predictions):\n",
        "    labels = [np.argmax(y) for y in Y]\n",
        "    return np.mean(np.array(predictions) == np.array(labels))"
      ],
      "metadata": {
        "id": "jjsxwYcmaXMK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NeuralNets(64, 30, 10, act=\"sigmoid\")\n",
        "model1.train(X_train_scaled, y_train_one_hot, learning_rate=0.01, epochs=200)\n",
        "\n",
        "y_predicted = model1.predict(X_test_scaled)\n",
        "accuracy_score = model1.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with sigmoid activation fn: {accuracy_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWxb3YHqdpmz",
        "outputId": "df904fea-548f-4fac-ae96-8e25f88dfd13"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.5991649269311065\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.9464161447459986\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.9596381350034795\n",
            "Epoch 60 completed ---------------->\n",
            "The accuracy score is 0.9665970772442589\n",
            "Epoch 80 completed ---------------->\n",
            "The accuracy score is 0.9721642310368824\n",
            "Epoch 100 completed ---------------->\n",
            "The accuracy score is 0.9728601252609603\n",
            "Epoch 120 completed ---------------->\n",
            "The accuracy score is 0.9770354906054279\n",
            "Epoch 140 completed ---------------->\n",
            "The accuracy score is 0.9798190675017397\n",
            "Epoch 160 completed ---------------->\n",
            "The accuracy score is 0.9826026443980515\n",
            "Epoch 180 completed ---------------->\n",
            "The accuracy score is 0.9839944328462074\n",
            "The predicted score on the test set with sigmoid activation fn: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = NeuralNets(64, 30, 10, act=\"relu\")\n",
        "model2.train(X_train_scaled, y_train_one_hot, learning_rate=0.15, epochs=200)\n",
        "\n",
        "y_predicted = model2.predict(X_test_scaled)\n",
        "accuracy_score = model2.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with relu activation fn: {accuracy_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Y7gANAfLCV",
        "outputId": "a2435d8e-b372-4ed7-dde1-85055a9c52d8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 60 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 80 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 100 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 120 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 140 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 160 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "Epoch 180 completed ---------------->\n",
            "The accuracy score is 0.10090466249130133\n",
            "The predicted score on the test set with relu activation fn: 0.09166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NeuralNets(64, 30, 10, act=\"tanh\")\n",
        "model3.train(X_train_scaled, y_train_one_hot, learning_rate=0.01, epochs=200)\n",
        "\n",
        "y_predicted = model3.predict(X_test_scaled)\n",
        "accuracy_score = model3.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with tanh activation fn: {accuracy_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjvoQ5cap2vR",
        "outputId": "a1a42e41-4ddd-4a7e-98a4-11a6e091fce0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.535142658315936\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.8677800974251914\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.9178844815588031\n",
            "Epoch 60 completed ---------------->\n",
            "The accuracy score is 0.9283228949199722\n",
            "Epoch 80 completed ---------------->\n",
            "The accuracy score is 0.9436325678496869\n",
            "Epoch 100 completed ---------------->\n",
            "The accuracy score is 0.9519832985386222\n",
            "Epoch 120 completed ---------------->\n",
            "The accuracy score is 0.9631176061238692\n",
            "Epoch 140 completed ---------------->\n",
            "The accuracy score is 0.9624217118997912\n",
            "Epoch 160 completed ---------------->\n",
            "The accuracy score is 0.965205288796103\n",
            "Epoch 180 completed ---------------->\n",
            "The accuracy score is 0.9638135003479471\n",
            "The predicted score on the test set with tanh activation fn: 0.9416666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Experiment on your own selected different hyper-parameters -> number of epochs and the learning rate\n",
        "# 4. Report your findings."
      ],
      "metadata": {
        "id": "rH44c26jjIGn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting different learning rate and epochs with sigmoid activation function\n",
        "\n",
        "print(f\"With learning rate={0.000001} and epochs={50}\")\n",
        "model4 = NeuralNets(64, 30, 10, act=\"sigmoid\")\n",
        "model4.train(X_train_scaled, y_train_one_hot, learning_rate=0.000001, epochs=50)\n",
        "\n",
        "y_predicted = model4.predict(X_test_scaled)\n",
        "accuracy_score = model4.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with sigmoid activation fn: {accuracy_score}\\n\")\n",
        "\n",
        "print(f\"With learning rate={0.0001} and epochs={100}\")\n",
        "model5 = NeuralNets(64, 30, 10, act=\"sigmoid\")\n",
        "model5.train(X_train_scaled, y_train_one_hot, learning_rate=0.0001, epochs=100)\n",
        "\n",
        "y_predicted = model5.predict(X_test_scaled)\n",
        "accuracy_score = model5.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with sigmoid activation fn: {accuracy_score}\\n\")\n",
        "\n",
        "print(f\"With learning rate={0.01} and epochs={500}\")\n",
        "model6 = NeuralNets(64, 30, 10, act=\"sigmoid\")\n",
        "model6.train(X_train_scaled, y_train_one_hot, learning_rate=0.1, epochs=400)\n",
        "\n",
        "y_predicted = model6.predict(X_test_scaled)\n",
        "accuracy_score = model6.accuracy(y_test_one_hot, y_predicted)\n",
        "print(f\"The predicted score on the test set with sigmoid activation fn: {accuracy_score}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJwqh5ojJZB",
        "outputId": "44a57d28-7c4f-4075-ae6d-50bc85a0f542"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With learning rate=1e-06 and epochs=50\n",
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.09116214335421016\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.09046624913013222\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.0918580375782881\n",
            "The predicted score on the test set with sigmoid activation fn: 0.09444444444444444\n",
            "\n",
            "With learning rate=0.0001 and epochs=100\n",
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.10786360473208072\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.23451635351426584\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.3583855254001392\n",
            "Epoch 60 completed ---------------->\n",
            "The accuracy score is 0.46903270702853167\n",
            "Epoch 80 completed ---------------->\n",
            "The accuracy score is 0.5567153792623522\n",
            "The predicted score on the test set with sigmoid activation fn: 0.6\n",
            "\n",
            "With learning rate=0.01 and epochs=500\n",
            "Epoch 0 completed ---------------->\n",
            "The accuracy score is 0.9137091162143354\n",
            "Epoch 20 completed ---------------->\n",
            "The accuracy score is 0.9867780097425192\n",
            "Epoch 40 completed ---------------->\n",
            "The accuracy score is 0.988865692414753\n",
            "Epoch 60 completed ---------------->\n",
            "The accuracy score is 0.9909533750869868\n",
            "Epoch 80 completed ---------------->\n",
            "The accuracy score is 0.9951287404314544\n",
            "Epoch 100 completed ---------------->\n",
            "The accuracy score is 0.9972164231036882\n",
            "Epoch 120 completed ---------------->\n",
            "The accuracy score is 0.9958246346555324\n",
            "Epoch 140 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "Epoch 160 completed ---------------->\n",
            "The accuracy score is 0.9944328462073765\n",
            "Epoch 180 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "Epoch 200 completed ---------------->\n",
            "The accuracy score is 0.9958246346555324\n",
            "Epoch 220 completed ---------------->\n",
            "The accuracy score is 0.9951287404314544\n",
            "Epoch 240 completed ---------------->\n",
            "The accuracy score is 0.9944328462073765\n",
            "Epoch 260 completed ---------------->\n",
            "The accuracy score is 0.9930410577592206\n",
            "Epoch 280 completed ---------------->\n",
            "The accuracy score is 0.9958246346555324\n",
            "Epoch 300 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "Epoch 320 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "Epoch 340 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "Epoch 360 completed ---------------->\n",
            "The accuracy score is 0.9972164231036882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-35c465fd1616>:2: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid_output = 1 / (1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 380 completed ---------------->\n",
            "The accuracy score is 0.9965205288796103\n",
            "The predicted score on the test set with sigmoid activation fn: 0.9416666666666667\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In experimenting with different learning rates and epochs, the results indicate significant impacts on model training and performance. With a very low learning rate of 0.000001, the model barely learned, achieving about 9% accuracy across 50 epochs. Increasing the learning rate to 0.0001 for 100 epochs improved accuracy significantly, reaching 60% on the test set, showing that a slightly higher rate facilitated better learning. However, the highest learning rate of 0.01, used over 500 epochs, quickly boosted the accuracy to over 99%, although it caused numerical stability issues like overflow in sigmoid computations. This suggests that while a higher learning rate can accelerate learning, it may also lead to potential instability, indicating the need for a balanced approach in setting the learning rate to ensure both effective learning and numerical stability."
      ],
      "metadata": {
        "id": "0-fJiLeGk-l-"
      }
    }
  ]
}