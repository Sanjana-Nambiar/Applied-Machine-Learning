{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1dc5da7-b80a-4fa9-aab8-063a6774a9e8",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee0d7ace-615e-4f0c-a666-8ff99f8b06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61544871-9294-423c-a5c5-a83b269230fc",
   "metadata": {},
   "source": [
    "### 1. Load dataset (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4d786f-bd75-4eaa-9b6a-3edba8035ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  class\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "iris_df= iris_df.replace({'Iris-setosa':0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "iris_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dca5d3e-b78a-48ec-8b73-59046a3ce3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase_df = pd.read_csv(\"spambase.csv\")\n",
    "spambase_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6cce16d-408b-4a13-9fab-448565a65c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the df into X and y for both the datasets\n",
    "X_iris =  iris_df.drop(\"class\", axis=1).to_numpy()\n",
    "y_iris = iris_df[\"class\"].to_numpy()\n",
    "X_spambase =  spambase_df.drop(\"1\", axis=1).to_numpy()\n",
    "y_spambase = spambase_df[\"1\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a22acb-b47e-4d97-b97b-faa8a6d2cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets for both the datasets \n",
    "# X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "# X_train_spambase, X_test_spambase, y_train_spambase, y_test_spambase = train_test_split(X_spambase, y_spambase, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90bd1a-48b3-41eb-b028-01fd12a30990",
   "metadata": {},
   "source": [
    "### 2. - 6. Create_decision_tree method (40) - Finding best feature and threshold to split (20) - Finding the dominant class label in the node (5) - Calculating entropy (5) - Predict function (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c2a37ba-85b2-4e3f-b57a-2b7f5b7d2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature \n",
    "        self.threshold = threshold \n",
    "        self.left = left \n",
    "        self.right = right \n",
    "        self.value = value \n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None         \n",
    "\n",
    "class decision_tree():  \n",
    "    def __init__(self, n_min_samples=None):\n",
    "        self.n_min_samples = n_min_samples\n",
    "        self.root = None \n",
    "        \n",
    "    def fit(self, X, y ):\n",
    "        self.root =  self._build_tree(X, y) \n",
    "   \n",
    "    # function that would facilitate in creating the child nodes based on the critriea \n",
    "    # its an iterative way of creating the tree so n_samp and n_feat could be the childern splits as well\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_labels =  len(np.unique(y))\n",
    "        \n",
    "        # check the stopping critriea \n",
    "        # in this case the stopping critriea is based on the min of number of instances in a node\n",
    "        if(n_labels == 1 or X.shape[0] < self.n_min_samples):\n",
    "            leaf_value = self._common_label(y) # returning the class identifies\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        idxs = np.arange(0, X.shape[1])\n",
    "        np.random.shuffle(idxs)\n",
    "        feat, thresh = self._best_split(X, y, idxs) # find the best split\n",
    "   \n",
    "        # create the child nodes \n",
    "        left_idx, right_idx = self._split(X[:, feat], thresh)\n",
    "        left = self._build_tree(X[left_idx, :], y[left_idx], depth+1)\n",
    "        right = self._build_tree(X[right_idx, :], y[right_idx], depth+1)\n",
    "        \n",
    "        return(Node(feat, thresh, left, right))\n",
    "                               \n",
    "    def _best_split(self, X, y, idxs):\n",
    "        best_gain = -1\n",
    "        best_feat, best_thresh = None, None # the feature that has the most information gain per given column\n",
    "\n",
    "        for idx in idxs: # for all feature columns\n",
    "            col = X[:, idx]\n",
    "            thresholds = np.sort(np.unique(col)) \n",
    "            # Take the average of two consecutive numbers as the splitting threshold\n",
    "            avg_thresholds = (thresholds[:-1] + thresholds[1:])/2  \n",
    "        \n",
    "            for thr in avg_thresholds: # information gain for all uniq vals\n",
    "                gain  = self._information_gain(y, col, thr)\n",
    "\n",
    "                if gain > best_gain: # finding the feature amongst the features that has the best gain \n",
    "                    best_gain = gain \n",
    "                    best_feat = idx\n",
    "                    best_thresh = thr\n",
    "                    \n",
    "        return best_feat, best_thresh\n",
    "        \n",
    "    # Calculate the Information Gain for all the unique numbers in the column, \n",
    "    # then pick the one with the highest Information Gain.\n",
    "    def _information_gain(self, y, x_column, threshold):\n",
    "        #entropy of the parent \n",
    "        parent_ent = self._entropy(y)\n",
    "        \n",
    "        # creating the split\n",
    "        left_idx, right_idx = self._split(x_column, threshold)\n",
    "        if len(left_idx) == 0 or len(right_idx) == 0: \n",
    "            return 0\n",
    "        \n",
    "        # calculating the weighted avg. of the child entropy\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idx), len(right_idx)\n",
    "        e_l, e_r = self._entropy(y[left_idx]), self._entropy(y[right_idx])\n",
    "        child_ent = (n_l/n)*e_l + (n_r/n)*e_r\n",
    "    \n",
    "        #information gain formula \n",
    "        inf_gain = parent_ent - child_ent\n",
    "        return inf_gain      \n",
    "        \n",
    "    def _split(self, x_column, split_thresh):\n",
    "        left_idxs = np.where(x_column <= split_thresh)[0]\n",
    "        right_idxs = np.where(x_column > split_thresh)[0]\n",
    "        return left_idxs, right_idxs     \n",
    "        \n",
    "    def _entropy(self, y):\n",
    "        _, occurence  = np.unique(y, return_counts=True) #array or uniq values and coressponding cts\n",
    "        prob = occurence/len(y)\n",
    "        # entropy  =  - sum_of_( prob * log(prob) )\n",
    "        return -np.sum([p*np.log(p) for p in prob if p>0])      \n",
    "    \n",
    "    def _common_label(self, y):\n",
    "        unique_labels, counts = np.unique(y, return_counts=True) #array or uniq values and coressponding cts\n",
    "        common_index = np.argmax(counts) # both the arrays are connected \n",
    "        common_label = unique_labels[common_index]\n",
    "        return common_label       \n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = [] # storing all the predictions\n",
    "        for x in X:\n",
    "            node = self.root # starting traversing from root\n",
    "            while not node.is_leaf():\n",
    "                if x[node.feature] <= node.threshold: # based on thr rule created while splitting \n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            predictions.append(node.value)\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb252b39-0396-4e9e-8d41-c4c75e867f03",
   "metadata": {},
   "source": [
    "### 7.& 8. Testing on Iris Dataset (Accuracy for different Nmin) (10) - Testing on Spam email Dataset (Accuracy for different Nmin)\t(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "505f1b96-7849-4610-9575-fd86f74e61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8., 15., 23., 30.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_min_iris = np.array([5, 10, 15, 20])\n",
    "n_samples_iris = np.ceil(n_min_iris/100 * X_iris.shape[0])\n",
    "n_samples_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51855ade-0571-4307-9f3b-d28bd64a7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 230.,  460.,  690.,  920., 1150.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_min_spambase = np.array([5, 10, 15, 20, 25])\n",
    "n_samples_spambase = np.ceil(n_min_spambase/100 * X_spambase.shape[0])\n",
    "n_samples_spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fd6d3f9-5928-48bf-b9c7-dfe33dd5e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common function for both\n",
    "def pred_accuracy(n_samples, X, y):\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    for n_min in n_samples:\n",
    "        accuracies = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            \n",
    "            # Split the data into training and test sets\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "            model = decision_tree(n_min_samples=n_min) \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "            accuracies.append(accuracy_score(y_test, y_pred, normalize=True))\n",
    "        \n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        accuracy_scores.append({\"Mean Accuracy\": mean_accuracy, \"Standard Deviation\": std_accuracy})\n",
    "        \n",
    "    return accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "570d4338-91bb-4b64-9228-ff495d0198b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_iris), len(y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4bcad2a-05a9-4159-99cb-cb18b6a235aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_min values: [ 8. 15. 23. 30.]:\n",
      " The corresponding accuarcy scores and the standard deviations are:\n",
      " [{'Mean Accuracy': 0.96, 'Standard Deviation': 0.03265986323710903}, {'Mean Accuracy': 0.96, 'Standard Deviation': 0.04422166387140532}, {'Mean Accuracy': 0.9466666666666667, 'Standard Deviation': 0.04988876515698587}, {'Mean Accuracy': 0.9400000000000001, 'Standard Deviation': 0.06289320754704401}]\n"
     ]
    }
   ],
   "source": [
    "scores_iris =  pred_accuracy(n_samples_iris, X_iris, y_iris)\n",
    "\n",
    "print(f\"For n_min values: {n_samples_iris}:\")\n",
    "print(f\" The corresponding accuarcy scores and the standard deviations are:\\n {scores_iris}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a148d7ed-ea29-48b8-81f0-1350c7b50f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_min values: [ 230.  460.  690.  920. 1150.]:\n",
      " The corresponding accuarcy scores and the standard deviations are:\n",
      " [ 230.  460.  690.  920. 1150.]\n"
     ]
    }
   ],
   "source": [
    "scores_spambase =  pred_accuracy(n_samples_spambase, X_spambase, y_spambase)\n",
    "\n",
    "print(f\"For n_min values: {n_samples_spambase}:\")\n",
    "print(f\" The corresponding accuarcy scores and the standard deviations are:\\n {n_samples_spambase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c4d7297-f3f5-44ce-bb19-4b3303c5b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Mean Accuracy': 0.9069565217391304,\n",
       "  'Standard Deviation': 0.012442685235873194},\n",
       " {'Mean Accuracy': 0.8908695652173912,\n",
       "  'Standard Deviation': 0.013534245579368163},\n",
       " {'Mean Accuracy': 0.866521739130435,\n",
       "  'Standard Deviation': 0.017205529510790744},\n",
       " {'Mean Accuracy': 0.8432608695652174,\n",
       "  'Standard Deviation': 0.02090689595986808},\n",
       " {'Mean Accuracy': 0.8321739130434782,\n",
       "  'Standard Deviation': 0.019219161830695962}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_spambase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
